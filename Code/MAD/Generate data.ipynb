{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emil/anaconda3/envs/py37/lib/python3.7/site-packages/statsmodels/tsa/statespace/varmax.py:159: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  EstimationWarning)\n",
      "/Users/Emil/anaconda3/envs/py37/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARMA \n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "arparams=np.array([.9,-.7])\n",
    "maparams=np.array([.5,.8])\n",
    "ar=np.r_[1,-arparams]\n",
    "ma=np.r_[1,maparams]\n",
    "obs=10000\n",
    "sigma=1\n",
    "\n",
    "# for the VARMA\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX \n",
    "\n",
    "# generate a a 2-D correlated normal series\n",
    "mean = [0,0]\n",
    "cov = [[1,0.9],[0.9,1]]\n",
    "data = np.random.multivariate_normal(mean,cov,100)\n",
    "\n",
    "# fit the data into a VARMA model\n",
    "model = VARMAX(data, order=(1,1))\n",
    "result = model.fit()\n",
    "sample = model.simulate(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module statsmodels.tsa.statespace.mlemodel:\n",
      "\n",
      "fit(self, start_params=None, transformed=True, cov_type='opg', cov_kwds=None, method='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, **kwargs)\n",
      "    Fits the model by maximum likelihood via Kalman filter.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start_params : array_like, optional\n",
      "        Initial guess of the solution for the loglikelihood maximization.\n",
      "        If None, the default is given by Model.start_params.\n",
      "    transformed : boolean, optional\n",
      "        Whether or not `start_params` is already transformed. Default is\n",
      "        True.\n",
      "    cov_type : str, optional\n",
      "        The `cov_type` keyword governs the method for calculating the\n",
      "        covariance matrix of parameter estimates. Can be one of:\n",
      "    \n",
      "        - 'opg' for the outer product of gradient estimator\n",
      "        - 'oim' for the observed information matrix estimator, calculated\n",
      "          using the method of Harvey (1989)\n",
      "        - 'approx' for the observed information matrix estimator,\n",
      "          calculated using a numerical approximation of the Hessian matrix.\n",
      "        - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "          matrix that may be valid even in the presense of some\n",
      "          misspecifications. Intermediate calculations use the 'oim'\n",
      "          method.\n",
      "        - 'robust_approx' is the same as 'robust' except that the\n",
      "          intermediate calculations use the 'approx' method.\n",
      "        - 'none' for no covariance matrix calculation.\n",
      "    cov_kwds : dict or None, optional\n",
      "        A dictionary of arguments affecting covariance matrix computation.\n",
      "    \n",
      "        **opg, oim, approx, robust, robust_approx**\n",
      "    \n",
      "        - 'approx_complex_step' : boolean, optional - If True, numerical\n",
      "          approximations are computed using complex-step methods. If False,\n",
      "          numerical approximations are computed using finite difference\n",
      "          methods. Default is True.\n",
      "        - 'approx_centered' : boolean, optional - If True, numerical\n",
      "          approximations computed using finite difference methods use a\n",
      "          centered approximation. Default is False.\n",
      "    method : str, optional\n",
      "        The `method` determines which solver from `scipy.optimize`\n",
      "        is used, and it can be chosen from among the following strings:\n",
      "    \n",
      "        - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "        - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "        - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "        - 'powell' for modified Powell's method\n",
      "        - 'cg' for conjugate gradient\n",
      "        - 'ncg' for Newton-conjugate gradient\n",
      "        - 'basinhopping' for global basin-hopping solver\n",
      "    \n",
      "        The explicit arguments in `fit` are passed to the solver,\n",
      "        with the exception of the basin-hopping solver. Each\n",
      "        solver has several optional arguments that are not the same across\n",
      "        solvers. See the notes section below (or scipy.optimize) for the\n",
      "        available arguments and for the list of explicit arguments that the\n",
      "        basin-hopping solver supports.\n",
      "    maxiter : int, optional\n",
      "        The maximum number of iterations to perform.\n",
      "    full_output : boolean, optional\n",
      "        Set to True to have all available output in the Results object's\n",
      "        mle_retvals attribute. The output is dependent on the solver.\n",
      "        See LikelihoodModelResults notes section for more information.\n",
      "    disp : boolean, optional\n",
      "        Set to True to print convergence messages.\n",
      "    callback : callable callback(xk), optional\n",
      "        Called after each iteration, as callback(xk), where xk is the\n",
      "        current parameter vector.\n",
      "    return_params : boolean, optional\n",
      "        Whether or not to return only the array of maximizing parameters.\n",
      "        Default is False.\n",
      "    optim_score : {'harvey', 'approx'} or None, optional\n",
      "        The method by which the score vector is calculated. 'harvey' uses\n",
      "        the method from Harvey (1989), 'approx' uses either finite\n",
      "        difference or complex step differentiation depending upon the\n",
      "        value of `optim_complex_step`, and None uses the built-in gradient\n",
      "        approximation of the optimizer. Default is None. This keyword is\n",
      "        only relevant if the optimization method uses the score.\n",
      "    optim_complex_step : bool, optional\n",
      "        Whether or not to use complex step differentiation when\n",
      "        approximating the score; if False, finite difference approximation\n",
      "        is used. Default is True. This keyword is only relevant if\n",
      "        `optim_score` is set to 'harvey' or 'approx'.\n",
      "    optim_hessian : {'opg','oim','approx'}, optional\n",
      "        The method by which the Hessian is numerically approximated. 'opg'\n",
      "        uses outer product of gradients, 'oim' uses the information\n",
      "        matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "        approximation. This keyword is only relevant if the\n",
      "        optimization method uses the Hessian matrix.\n",
      "    **kwargs\n",
      "        Additional keyword arguments to pass to the optimizer.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    MLEResults\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    statsmodels.base.model.LikelihoodModel.fit\n",
      "    MLEResults\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(VARMAX.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
