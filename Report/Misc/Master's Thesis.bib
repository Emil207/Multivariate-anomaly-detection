Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Rumelhart1986,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure 1. {\textcopyright} 1986 Nature Publishing Group.},
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/naturebp.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Humanities and Social Sciences,Science,multidisciplinary},
month = {oct},
number = {6088},
pages = {533--536},
publisher = {Nature Publishing Group},
title = {{Learning representations by back-propagating errors}},
url = {http://www.nature.com/articles/323533a0},
volume = {323},
year = {1986}
}
@article{Song2018,
abstract = {With widespread adoption of electronic health records, there is an increased emphasis for predictive models that can effectively deal with clinical time-series data. Powered by Recurrent Neural Network (RNN) architectures with Long Short-Term Memory (LSTM) units, deep neural networks have achieved state-of-the-art results in several clinical prediction tasks. Despite the success of RNNs, its sequential nature prohibits parallelized computing, thus making it inefficient particularly when processing long sequences. Recently, architectures which are based solely on attention mechanisms have shown remarkable success in transduction tasks in NLP, while being computationally superior. In this paper, for the first time, we utilize attention models for clinical time-series modeling, thereby dispensing recurrence entirely. We develop the SAnD (Simply Attend and Diagnose) architecture, which employs a masked, self-attention mechanism, and uses positional encoding and dense interpolation strategies for incorporating temporal order. Furthermore, we develop a multi-task variant of SAnD to jointly infer models with multiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we demonstrate that the proposed approach achieves state-of-the-art performance in all tasks, outperforming LSTM models and classical baselines with hand-engineered features.},
archivePrefix = {arXiv},
arxivId = {1711.03905},
author = {Song, Huan and Rajan, Deepta and Thiagarajan, Jayaraman J. and Spanias, Andreas},
eprint = {1711.03905},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/16325-77574-1-PB.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
keywords = {Machine Learning Methods Track},
pages = {4091--4098},
title = {{Attend and diagnose: Clinical time series analysis using attention models}},
year = {2018}
}
@article{Sandsten2018,
author = {Sandsten, Maria},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Sandsten - 2018 - Time-Frequency Analysis of Time-Varying Signals and Non-Stationary Processes.pdf:pdf},
title = {{Time-Frequency Analysis of Time-Varying Signals and Non-Stationary Processes}},
year = {2018}
}
@inproceedings{Ding2018,
abstract = {Aiming at the anomaly detection in multivariate time series(MTS), we propose a real-time anomaly detection algorithm in MTS based on Hierarchical Temporal Memory(HTM) and Bayesian Network(BN), called RADM. First of all, we use HTM model to evaluate the real-time anomalies of each univariate time series(UTS) in MTS. Secondly, a model of anomalous state detection in MTS based on Naive Bayesian is designed to analyze the validity of the above MTS. Lastly, considering the real-time monitoring cases of the system states of terminal nodes in Cloud Platform, we utilize ternary time series of CPU utilization, Network speed and Memory occupancy ratio as data samples, and through the experimental simulation, we verify that RADM proposed in this paper can take advantage of the specific relevance in MTS and make a more effective judgment on the system anomalies.},
author = {Ding, Nan and Gao, Huanbo and Bu, Hongyu and Ma, Haoxuan},
booktitle = {Proceedings - 2018 IEEE International Conference on Smart Internet of Things, SmartIoT 2018},
doi = {10.1109/SmartIoT.2018.00-13},
isbn = {9781538685426},
keywords = {Anomaly detection,Bayesian network,Hierarchical temporal memory,Multivariate time series},
month = {sep},
pages = {129--134},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{RADM: Real-time anomaly detection in multivariate time series based on Bayesian network}},
year = {2018}
}
@article{Mirza2014,
abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
archivePrefix = {arXiv},
arxivId = {1411.1784},
author = {Mirza, Mehdi and Osindero, Simon},
eprint = {1411.1784},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Mirza, Osindero - Unknown - Conditional Generative Adversarial Nets.pdf:pdf},
title = {{Conditional Generative Adversarial Nets}},
url = {https://arxiv.org/pdf/1411.1784.pdf http://arxiv.org/abs/1411.1784},
year = {2014}
}
@inproceedings{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.3156/jsoft.29.5_177_2},
eprint = {1406.2661},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow et al. - Unknown - Generative Adversarial Nets.pdf:pdf},
issn = {10495258},
number = {January},
pages = {2672--2680},
title = {{Generative adversarial nets}},
url = {http://www.github.com/goodfeli/adversarial},
volume = {3},
year = {2014}
}
@inproceedings{Nanduri2016,
abstract = {Anomaly Detection in multivariate, time-series data collected from aircraft's Flight Data Recorder (FDR) or Flight Operational Quality Assurance (FOQA) data provide a powerful means for identifying events and trends that reduce safety margins. The industry standard Exceedance Detection algorithm uses a list of specified parameters and their thresholds to identify known deviations. In contrast, Machine Learning algorithms detect unknown unusual patterns in the data either through semi-supervised or unsupervised learning. The Multiple Kernel Anomaly Detection (MKAD) algorithm based on One-class SVM identified 6 of 11 canonical anomalies in a large dataset but is limited by the need for dimensionality reduction, poor sensitivity to short term anomalies, and inability to detect anomalies in latent features. This paper describes the application of Recurrent Neural Networks (RNN) with Long Term Short Term Memory (LTSM) and Gated Recurrent Units (GRU) architectures which can overcome the limitations described above. The RNN algorithms detected 9 out the 11 anomalies in the test dataset with Precision = 1, Recall = 0.818 and F1 score = 0.89. RNN architectures, designed for time-series data, are suited for implementation on the flight deck to provide real-time anomaly detection. The implications of these results are discussed.},
author = {Nanduri, Anvardh and Sherry, Lance},
booktitle = {ICNS 2016: Securing an Integrated CNS System to Meet Future Challenges},
doi = {10.1109/ICNSURV.2016.7486356},
isbn = {9781509021499},
month = {jun},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Anomaly detection in aircraft data using Recurrent Neural Networks (RNN)}},
year = {2016}
}
@book{Goodfellow2016a,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
publisher = {MIT Press},
title = {{Deep Learning}},
url = {https://www.deeplearningbook.org/},
year = {2016}
}
@article{Tatbul2018,
abstract = {Classical anomaly detection is principally concerned with point-based anomalies, those anomalies that occur at a single point in time. Yet, many real-world anomalies are range-based, meaning they occur over a period of time. Motivated by this observation, we present a new mathematical model to evaluate the accuracy of time series classification algorithms. Our model expands the well-known Precision and Recall metrics to measure ranges, while simultaneously enabling customization support for domain-specific preferences.},
author = {Tatbul, Nesime and Lee, Tae Jun and Zdonik, Stan and Alam, Mejbah and Gottschlich, Justin},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1920--1930},
title = {{Precision and recall for time series}},
volume = {2018-Decem},
year = {2018}
}
@inproceedings{Song2017,
abstract = {Existing Markov Chain Monte Carlo (MCMC) methods are either based on generalpurpose and domain-agnostic schemes, which can lead to slow convergence, or problem-specific proposals hand-crafted by an expert. In this paper, we propose A-NICE-MC, a novel method to automatically design efficient Markov chain kernels tailored for a specific domain. First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo.},
archivePrefix = {arXiv},
arxivId = {1706.07561},
author = {Song, Jiaming and Zhao, Shengjia and Ermon, Stefano},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1706.07561},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Song, Zhao, Ermon - Unknown - A-NICE-MC Adversarial Training for MCMC.pdf:pdf},
issn = {10495258},
pages = {5141--5151},
title = {{A-NICE-MC: Adversarial training for MCMC}},
url = {https://pdfs.semanticscholar.org/ff1e/e941c8fe334afd7dcd92b5c4478c0ae16efe.pdf},
volume = {2017-Decem},
year = {2017}
}
@article{DeMeerPardo2019,
abstract = {The scarcity of historical financial data has been a huge hindrance for the development algorithmic trading models ever since the first models were devised. Most financial models assume as hypothesis a series of characteristics regarding the nature of financial time series and seek extracting information about the state of the market through calibration. Through backtesting, a large number of these models are seen not to perform and are thus discarded. The remaining well-performing models however, are highly vulnerable to overfitting. Financial time series are complex by nature and their behaviour changes over time, so this concern is well founded. In addition to the problem of overfitting, available data is far too scarce for most machine learning applications and impossibly scarce for advanced approaches such as reinforcement learning, which has heavily impaired the application of these novel techniques in financial settings. This is where data generation comes into play. Generative Adversarial Networks, GANs, are a type of neural network architecture that focuses on sample generation. Through adversarial training, the GAN can learn the underlying structure of the input data and become able to generate samples very similar to those of the data distribution. This is specially useful in the case of high-dimensional objects, in which the dimensions are heavily inter-dependent, such as images, music and in our case financial time series. In this work we want to explore the generating capabilities of GANs applied to financial time series and investigate whether or not we can generate realistic financial scenarios.},
author = {{De Meer Pardo}, Fernando},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/Enriching{\_}Financial{\_}Datasets{\_}with{\_}Generative{\_}Adversarial{\_}Networks.pdf:pdf},
number = {July},
title = {{Enriching Financial Datasets with Generative Adversarial Networks}},
url = {https://repository.tudelft.nl/islandora/object/uuid:51d69925-fb7b-4e82-9ba6-f8295f96705c},
year = {2019}
}
@book{Aggarwal2013,
abstract = {Signatur 1562/310},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Aggarwal, Charu C.},
booktitle = {Outlier Analysis},
doi = {10.1007/978-1-4614-6396-2},
eprint = {arXiv:1011.1669v3},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Aggarwal - 2013 - Outlier analysis (book).pdf:pdf},
isbn = {9781461463962},
issn = {1935-8237},
pages = {1--446},
pmid = {25246403},
title = {{Outlier analysis (book)}},
year = {2013}
}
@article{Goodfellow2016,
abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Goodfellow, Ian},
eprint = {1701.00160},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow - 2016 - NIPS 2016 Tutorial Generative Adversarial Networks(2).pdf:pdf},
title = {{NIPS 2016 Tutorial: Generative Adversarial Networks}},
url = {http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf http://arxiv.org/abs/1701.00160},
year = {2016}
}
@article{Li2019a,
abstract = {The prevalence of networked sensors and actuators in many real-world systems such as smart buildings, factories, power plants, and data centers generate substantial amounts of multivariate time series data for these systems. The rich sensor data can be continuously monitored for intrusion events through anomaly detection. However, conventional threshold-based anomaly detection methods are inadequate due to the dynamic complexities of these systems, while supervised machine learning methods are unable to exploit the large amounts of data due to the lack of labeled data. On the other hand, current unsupervised machine learning approaches have not fully exploited the spatial-temporal correlation and other dependencies amongst the multiple variables (sensors/actuators) in the system for detecting anomalies. In this work, we propose an unsupervised multivariate anomaly detection method based on Generative Adversarial Networks (GANs). Instead of treating each data stream independently, our proposed MAD-GAN framework considers the entire variable set concurrently to capture the latent interactions amongst the variables. We also fully exploit both the generator and discriminator produced by the GAN, using a novel anomaly score called DR-score to detect anomalies by discrimination and reconstruction. We have tested our proposed MAD-GAN using two recent datasets collected from real-world CPS: the Secure Water Treatment (SWaT) and the Water Distribution (WADI) datasets. Our experimental results showed that the proposed MAD-GAN is effective in reporting anomalies caused by various cyber-intrusions compared in these complex real-world systems.},
archivePrefix = {arXiv},
arxivId = {1901.04997},
author = {Li, Dan and Chen, Dacheng and Shi, Lei and Jin, Baihong and Goh, Jonathan and Ng, See-Kiong},
eprint = {1901.04997},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - MAD-GAN Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks.pdf:pdf},
month = {jan},
title = {{MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1901.04997},
year = {2019}
}
@inproceedings{Lipton2015,
abstract = {Clinical medical data, especially in the intensive care unit (ICU), consist of multivariate time series of observations. For each patient visit (or episode), sensor data and lab test results are recorded in the patient's Electronic Health Record (EHR). While potentially containing a wealth of insights, the data is difficult to mine effectively, owing to varying length, irregular sampling and missing data. Recurrent Neural Networks (RNNs), particularly those using Long Short-Term Memory (LSTM) hidden units, are powerful and increasingly popular models for learning from sequence data. They effectively model varying length sequences and capture long range dependencies. We present the first study to empirically evaluate the ability of LSTMs to recognize patterns in multivariate time series of clinical measurements. Specifically, we consider multilabel classification of diagnoses, training a model to classify 128 diagnoses given 13 frequently but irregularly sampled clinical measurements. First, we establish the effectiveness of a simple LSTM network for modeling clinical data. Then we demonstrate a straightforward and effective training strategy in which we replicate targets at each sequence step. Trained only on raw time series, our models outperform several strong baselines, including a multilayer perceptron trained on hand-engineered features.},
archivePrefix = {arXiv},
arxivId = {1511.03677},
author = {Lipton, Zachary C. and Kale, David C. and Elkan, Charles and Wetzel, Randall},
booktitle = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
eprint = {1511.03677},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Lipton et al. - 2015 - Learning to Diagnose with LSTM Recurrent Neural Networks.pdf:pdf},
month = {nov},
title = {{Learning to diagnose with LSTM recurrent neural networks}},
url = {https://arxiv.org/abs/1511.03677},
year = {2016}
}
@article{Brynolfsson2017,
abstract = {{\textcopyright} EURASIP 2017. In this paper we argue that the Wigner-Ville distribution (WVD), instead of the spectrogram, should be used as basic input into convolutional neural network (CNN) based classification schemes. The WVD has superior resolution and localization as compared to other time-frequency representations. We present a method where a large-size kernel may be learned from the data, to enhance features important for classification. We back up our claims with theory, as well as application on simulated examples and show superior performance as compared to the commonly used spectrogram.},
author = {Brynolfsson, Johan and Sandsten, Maria},
doi = {10.23919/EUSIPCO.2017.8081222},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Brynolfsson, Sandsten - 2017 - Classification of one-dimensional non-stationary signals using the Wigner-Ville distribution in convoluti.pdf:pdf},
isbn = {9780992862671},
journal = {25th European Signal Processing Conference, EUSIPCO 2017},
number = {0},
pages = {326--330},
title = {{Classification of one-dimensional non-stationary signals using the Wigner-Ville distribution in convolutional neural networks}},
volume = {2017-Janua},
year = {2017}
}
@article{Tatbul2018,
abstract = {Classical anomaly detection is principally concerned with point-based anomalies, those anomalies that occur at a single point in time. Yet, many real-world anomalies are range-based, meaning they occur over a period of time. Motivated by this observation, we present a new mathematical model to evaluate the accuracy of time series classification algorithms. Our model expands the well-known Precision and Recall metrics to measure ranges, while simultaneously enabling customization support for domain-specific preferences.},
author = {Tatbul, Nesime and Lee, Tae Jun and Zdonik, Stan and Alam, Mejbah and Gottschlich, Justin},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1920--1930},
title = {{Precision and recall for time series}},
volume = {2018-Decem},
year = {2018}
}
@article{Baragona2007,
abstract = {In multivariate time series, outlying data may be often observed that do not fit the common pattern. Occurrences of outliers are unpredictable events that may severely distort the analysis of the multivariate time series. For instance, model building, seasonality assessment, and forecasting may be seriously affected by undetected outliers. The structure dependence of the multivariate time series gives rise to the well-known smearing and masking phenomena that prevent using most outliers' identification techniques. It may be noticed, however, that a convenient way for representing multiple outliers consists of superimposing a deterministic disturbance to a gaussian multivariate time series. Then outliers may be modeled as nongaussian time series components. Independent component analysis is a recently developed tool that is likely to be able to extract possible outlier patterns. In practice, independent component analysis may be used to analyze multivariate observable time series and separate regular and outlying unobservable components. In the factor models framework too, it is shown that independent component analysis is a useful tool for detection of outliers in multivariate time series. Some algorithms that perform independent component analysis are compared. It has been found that all algorithms are effective in detecting various types of outliers, such as patches, level shifts, and isolated outliers, even at the beginning or the end of the stretch of observations. Also, there is no appreciable difference in the ability of different algorithms to display the outlying observations pattern.},
author = {Baragona, Roberto and Battaglia, Francesco},
doi = {10.1162/neco.2007.19.7.1962},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Baragona, Battaglia - 2007 - Outliers detection in multivariate time series by independent component analysis.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {7},
pages = {1962--1984},
title = {{Outliers detection in multivariate time series by independent component analysis}},
volume = {19},
year = {2007}
}
@article{Zhang2019a,
abstract = {Nowadays, multivariate time series data are increasingly collected in various real world systems, e.g., power plants, wearable devices, etc. Anomaly detection and diagnosis in multivariate time series refer to identifying abnormal status in certain time steps and pinpointing the root causes. Building such a system, however, is challenging since it not only requires to capture the temporal dependency in each time series, but also need encode the inter-correlations between different pairs of time series. In addition, the system should be robust to noise and provide operators with different levels of anomaly scores based upon the severity of different incidents. Despite the fact that a number of unsupervised anomaly detection algorithms have been developed, few of them can jointly address these challenges. In this paper, we propose a Multi-Scale Convolutional Recurrent Encoder-Decoder (MSCRED), to perform anomaly detection and diagnosis in multivariate time series data. Specifically, MSCRED first constructs multi-scale (resolution) signature matrices to characterize multiple levels of the system statuses in different time steps. Subsequently, given the signature matrices, a convolutional encoder is employed to encode the inter-sensor (time series) correlations and an attention based Convolutional Long-Short Term Memory (ConvLSTM) network is developed to capture the temporal patterns. Finally, based upon the feature maps which encode the inter-sensor correlations and temporal information, a convolutional decoder is used to reconstruct the input signature matrices and the residual signature matrices are further utilized to detect and diagnose anomalies. Extensive empirical studies based on a synthetic dataset and a real power plant dataset demonstrate that MSCRED can outperform state-ofthe-art baseline methods.},
archivePrefix = {arXiv},
arxivId = {1811.08055},
author = {Zhang, Chuxu and Song, Dongjin and Chen, Yuncong and Feng, Xinyang and Lumezanu, Cristian and Cheng, Wei and Ni, Jingchao and Zong, Bo and Chen, Haifeng and Chawla, Nitesh V.},
doi = {10.1609/aaai.v33i01.33011409},
eprint = {1811.08055},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/3942-Article Text-7001-2-10-20190726.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {Memory storage and retrieval, cognitive architectu},
pages = {1409--1416},
title = {{A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data}},
volume = {33},
year = {2019}
}
@article{Basora2019,
abstract = {Anomaly detection is an active area of research with numerous methods and applications. This survey reviews the state-of-the-art of data-driven anomaly detection techniques and their application to the aviation domain. After a brief introduction to the main traditional data-driven methods for anomaly detection, we review the recent advances in the area of neural networks, deep learning and temporal-logic based learning. In particular, we cover unsupervised techniques applicable to time series data because of their relevance to the aviation domain, where the lack of labeled data is the most usual case, and the nature of flight trajectories and sensor data is sequential, or temporal. The advantages and disadvantages of each method are presented in terms of computational efficiency and detection efficacy. The second part of the survey explores the application of anomaly detection techniques to aviation and their contributions to the improvement of the safety and performance of flight operations and aviation systems. As far as we know, some of the presented methods have not yet found an application in the aviation domain. We review applications ranging from the identification of significant operational events in air traffic operations to the prediction of potential aviation system failures for predictive maintenance.},
author = {Basora, Luis and Olive, Xavier and Dubot, Thomas},
doi = {10.3390/aerospace6110117},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/preprints201909.0326.v1.pdf:pdf},
issn = {22264310},
journal = {Aerospace},
keywords = {Air traffic management,Anomaly detection,Aviation,Condition monitoring,Deep learning,Machine learning,Predictive maintenance,Prognostics and health management,Time series,Trajectory},
number = {11},
pages = {1--27},
title = {{Recent advances in anomaly detection methods applied to aviation}},
volume = {6},
year = {2019}
}
@article{Huang2018,
abstract = {This abstract proposes a time series anomaly detector which 1) makes no assumption about the underlying mechanism of anomaly patterns, 2) refrains from the cumbersome work of threshold setting for good anomaly detection performance under specific scenarios, and 3) keeps evolving with the growth of anomaly detection experience. Essentially, the anomaly detector is powered by the Recurrent Neural Network (RNN) and adopts the Reinforcement Learning (RL) method to achieve the self-learning process. Our initial experiments demonstrate promising results of using the detector in network time series anomaly detection problems.},
author = {Huang, Chengqiang and Wu, Yulei and Zuo, Yuan and Pei, Ke and Min, Geyong},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/16048-77246-1-PB.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
keywords = {Student Abstract Program},
pages = {8087--8088},
title = {{Towards experienced anomaly detector through reinforcement learning}},
year = {2018}
}
@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
eprint = {1701.07875},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Arjovsky, Chintala, Bottou - 2017 - Wasserstein GAN.pdf:pdf},
month = {jan},
title = {{Wasserstein GAN}},
url = {https://arxiv.org/pdf/1701.07875.pdf http://arxiv.org/abs/1701.07875},
year = {2017}
}
@inproceedings{Gulrajani2017,
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
archivePrefix = {arXiv},
arxivId = {1704.00028},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1704.00028},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Gulrajani et al. - Unknown - Improved Training of Wasserstein GANs Montreal Institute for Learning Algorithms(2).pdf:pdf},
issn = {10495258},
pages = {5768--5778},
title = {{Improved training of wasserstein GANs}},
url = {https://github.com/igul222/improved{\_}wgan{\_}training.},
volume = {2017-Decem},
year = {2017}
}
@article{Malhotra2016,
abstract = {Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).},
archivePrefix = {arXiv},
arxivId = {1607.00148},
author = {Malhotra, Pankaj and Ramakrishnan, Anusha and Anand, Gaurangi and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
eprint = {1607.00148},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Malhotra et al. - 2016 - LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection.pdf:pdf},
title = {{LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection}},
url = {http://arxiv.org/abs/1607.00148},
year = {2016}
}
@article{Doan2019,
abstract = {Generative Adversarial Networks (GANs) can successfully approximate a probability distribution and produce realistic samples. However, open questions such as sufficient convergence conditions and mode collapse still persist. In this paper, we build on existing work in the area by proposing a novel framework for training the generator against an ensemble of discriminator networks, which can be seen as a one-student/multiple-teachers setting. We formalize this problem within the full-information adversarial bandit framework, where we evaluate the capability of an algorithm to select mixtures of discriminators for providing the generator with feedback during learning. To this end, we propose a reward function which reflects the progress made by the generator and dynamically update the mixture weights allocated to each discriminator. We also draw connections between our algorithm and stochastic optimization methods and then show that existing approaches using multiple discriminators in literature can be recovered from our framework. We argue that less expressive discriminators are smoother and have a general coarse grained view of the modes map, which enforces the generator to cover a wide portion of the data distribution support. On the other hand, highly expressive discriminators ensure samples quality. Finally, experimental results show that our approach improves samples quality and diversity over existing baselines by effectively learning a curriculum. These results also support the claim that weaker discriminators have higher entropy improving modes coverage.},
archivePrefix = {arXiv},
arxivId = {1808.00020},
author = {Doan, Thang and Monteiro, Jo{\~{a}}o and Albuquerque, Isabela and Mazoure, Bogdan and Durand, Audrey and Pineau, Joelle and Hjelm, R. Devon},
doi = {10.1609/aaai.v33i01.33013470},
eprint = {1808.00020},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/4224-Article Text-7278-1-10-20190705.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
pages = {3470--3477},
title = {{On-Line Adaptative Curriculum Learning for GANs}},
volume = {33},
year = {2019}
}
@article{Weng2019,
abstract = {Anomaly detection in many applications is becoming more and more important, especially for security and privacy in mobile service computing domains with the development of mobile internet and mobile cloud computing, in which data are typical multidimensional time series data. However, the collective anomaly detection for multidimensional streams exists lots of problems, owing to the differences between the anomaly detection in multidimensional time series and univariate time series data. For example, the temporal continuity of multidimensional time series is much weaker than univariate time series and it is unreasonable to judge the entire multidimensional data as an anomaly if a certain dimension is abnormal. In this paper, we consider the statistical features of the subsequence of streams, proposing a novel collective anomaly detection algorithm for multidimensional streams based on iForest in cloud environment, namely iForestFS. When using different features about mobile cloud services' metrics suggested by domain knowledge, iForestFS could detect different kinds of anomalies for mobile service security. Furthermore, we implement distributed iForestFS using spark framework in order to improve time performance and scalability. The experimental results performed on three datasets(mainly about network security) derived from UCI repository demonstrate that the proposed algorithm can effectively detect collective anomaly of multidimensional streams in security domain.},
author = {Weng, Yu and Liu, Lei},
doi = {10.1109/ACCESS.2019.2909750},
issn = {21693536},
journal = {IEEE Access},
keywords = {Collective anomaly detection,isolation forest,multidimensional stream processing,security in mobile service,time series},
pages = {49157--49168},
publisher = {IEEE},
title = {{A Collective Anomaly Detection Approach for Multidimensional Streams in Mobile Service Security}},
volume = {7},
year = {2019}
}
@article{Yoon2019a,
abstract = {We deconstruct the performance of GANs into three components: 1. Formulation: we propose a perturbation view of the population target of GANs. Building on this interpretation, we show that GANs can be viewed as a generalization of the robust statistics framework, and propose a novel GAN architecture, termed as Cascade GANs, to provably recover meaningful low-dimensional generator approximations when the real distribution is high-dimensional and corrupted by outliers. 2. Generalization: given a population target of GANs, we design a systematic principle, projection under admissible distance, to design GANs to meet the population requirement using finite samples. We implement our principle in three cases to achieve polynomial and sometimes near-optimal sample complexities: (1) learning an arbitrary generator under an arbitrary pseudonorm; (2) learning a Gaussian location family under TV distance, where we utilize our principle provide a new proof for the optimality of Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian approximation of a high-dimensional arbitrary distribution under Wasserstein distance. We demonstrate a fundamental trade-off in the approximation error and statistical error in GANs, and show how to apply our principle with empirical samples to predict how many samples are sufficient for GANs in order not to suffer from the discriminator winning problem. 3. Optimization: we demonstrate alternating gradient descent is provably not locally asymptotically stable in optimizing the GAN formulation of PCA. We diagnose the problem as the minimax duality gap being non-zero, and propose a new GAN architecture whose duality gap is zero, where the value of the game is equal to the previous minimax value (not the maximin value). We prove the new GAN architecture is globally asymptotically stable in optimization under alternating gradient descent.},
archivePrefix = {arXiv},
arxivId = {1901.09465},
author = {Yoon, Jinsung and Jarrett, Daniel and van der Schaar, Mahaela},
eprint = {1901.09465},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/8789-time-series-generative-adversarial-networks.pdf:pdf},
number = {NeurIPS},
pages = {1--11},
title = {{Time-Series Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1901.09465},
year = {2019}
}
@article{Malhotra2016a,
abstract = {Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).},
annote = {Prediction-based on univariate series.},
archivePrefix = {arXiv},
arxivId = {1607.00148},
author = {Malhotra, Pankaj and Ramakrishnan, Anusha and Anand, Gaurangi and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
eprint = {1607.00148},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Malhotra et al. - 2016 - LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection.pdf:pdf},
title = {{LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection}},
url = {http://arxiv.org/abs/1607.00148},
year = {2016}
}
@article{Schlegl2019,
abstract = {Obtaining expert labels in clinical imaging is difficult since exhaustive annotation is time-consuming. Furthermore, not all possibly relevant markers may be known and sufficiently well described a priori to even guide annotation. While supervised learning yields good results if expert labeled training data is available, the visual variability, and thus the vocabulary of findings, we can detect and exploit, is limited to the annotated lesions. Here, we present fast AnoGAN (f-AnoGAN), a generative adversarial network (GAN) based unsupervised learning approach capable of identifying anomalous images and image segments, that can serve as imaging biomarker candidates. We build a generative model of healthy training data, and propose and evaluate a fast mapping technique of new data to the GAN's latent space. The mapping is based on a trained encoder, and anomalies are detected via a combined anomaly score based on the building blocks of the trained model â€“ comprising a discriminator feature residual error and an image reconstruction error. In the experiments on optical coherence tomography data, we compare the proposed method with alternative approaches, and provide comprehensive empirical evidence that f-AnoGAN outperforms alternative approaches and yields high anomaly detection accuracy. In addition, a visual Turing test with two retina experts showed that the generated images are indistinguishable from real normal retinal OCT images. The f-AnoGAN code is available at https://github.com/tSchlegl/f-AnoGAN.},
author = {Schlegl, Thomas and Seeb{\"{o}}ck, Philipp and Waldstein, Sebastian M. and Langs, Georg and Schmidt-Erfurth, Ursula},
doi = {10.1016/j.media.2019.01.010},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/fastAnoGAN.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Anomaly detection,Optical coherence tomography,Unsupervised learning,Wasserstein generative adversarial network},
number = {May},
pages = {30--44},
title = {{f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks}},
volume = {54},
year = {2019}
}
@article{Liu2008,
abstract = {Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of profiles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and Random Forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies. {\textcopyright} 2008 IEEE.},
author = {Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi Hua},
doi = {10.1109/ICDM.2008.17},
isbn = {9780769535029},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
pages = {413--422},
publisher = {IEEE},
title = {{Isolation forest}},
year = {2008}
}
@article{Mei2016,
abstract = {Multivariate time series (MTS) datasets broadly exist in numerous fields, including health care, multimedia, finance, and biometrics. How to classify MTS accurately has become a hot research topic since it is an important element in many computer vision and pattern recognition applications. In this paper, we propose a Mahalanobis distance-based dynamic time warping (DTW) measure for MTS classification. The Mahalanobis distance builds an accurate relationship between each variable and its corresponding category. It is utilized to calculate the local distance between vectors in MTS. Then we use DTW to align those MTS which are out of synchronization or with different lengths. After that, how to learn an accurate Mahalanobis distance function becomes another key problem. This paper establishes a LogDet divergence-based metric learning with triplet constraint model which can learn Mahalanobis matrix with high precision and robustness. Furthermore, the proposed method is applied on nine MTS datasets selected from the University of California, Irvine machine learning repository and Robert T. Olszewski's homepage, and the results demonstrate the improved performance of the proposed approach.},
author = {Mei, Jiangyuan and Liu, Meizhu and Wang, Yuan Fang and Gao, Huijun},
doi = {10.1109/TCYB.2015.2426723},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Mei et al. - 2016 - Learning a Mahalanobis Distance-Based Dynamic Time Warping Measure for Multivariate Time Series Classification.pdf:pdf},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Dynamic time warping (DTW),Mahalanobis distance,metric learning,multivariate time series (MTS)},
number = {6},
pages = {1363--1374},
publisher = {IEEE},
title = {{Learning a Mahalanobis Distance-Based Dynamic Time Warping Measure for Multivariate Time Series Classification}},
volume = {46},
year = {2016}
}
@article{Cheng2013,
abstract = {Anomaly detection in multivariate time series is an important data mining task with applications to ecosystem modeling, network traffic monitoring, medical diagnosis, and other domains. This paper presents a robust algorithm for detecting anomalies in noisy multivariate time series data by employing a kernel matrix alignment method to capture the dependence relationships among variables in the time series. Anomalies are found by performing a random walk traversal on the graph induced by the aligned kernel matrix. We show that the algorithm is flexible enough to handle different types of time series anomalies including subsequence-based and local anomalies. Our framework can also be used to characterize the anomalies found in a target time series in terms of the anomalies present in other time series. We have performed extensive experiments to empirically demonstrate the effectiveness of our algorithm. A case study is also presented to illustrate the ability of the algorithm to detect ecosystem disturbances in Earth science data.},
author = {Cheng, Haibin and Tan, Pang-Ning and Potter, Christopher and Klooster, Steven},
doi = {10.1137/1.9781611972795.36},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Cheng et al. - 2013 - Detection and Characterization of Anomalies in Multivariate Time Series.pdf:pdf},
pages = {413--424},
title = {{Detection and Characterization of Anomalies in Multivariate Time Series}},
year = {2013}
}
@article{Esteban2017,
abstract = {Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from 'serialised' MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data.},
archivePrefix = {arXiv},
arxivId = {1706.02633},
author = {Esteban, Crist{\'{o}}bal and Hyland, Stephanie L and R{\"{a}}tsch, Gunnar},
eprint = {1706.02633},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Hyland et al. - 2015 - REAL-VALUED (MEDICAL) TIME SERIES GENERA-TION WITH RECURRENT CONDITIONAL GANS.pdf:pdf},
title = {{Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs}},
url = {https://arxiv.org/pdf/1706.02633v2.pdf http://arxiv.org/abs/1706.02633},
year = {2017}
}
@article{Zhang2019,
abstract = {In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GAXs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN performs better than prior work1, boosting the best published Inception score from 36.8 to 52.52 and reducing Fr{\'{e}}het Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.},
archivePrefix = {arXiv},
arxivId = {1805.08318},
author = {Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
eprint = {1805.08318},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/1805.08318.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
pages = {12744--12753},
title = {{Self-attention generative adversarial networks}},
volume = {2019-June},
year = {2019}
}
@inproceedings{Wang,
abstract = {We propose a simple but strong baseline for time series classification from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The proposed Fully Convolutional Network (FCN) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive. The global average pooling in our convolutional model enables the exploitation of the Class Activation Map (CAM) to find out the contributing region in the raw data for the specific labels. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classification semantics.},
archivePrefix = {arXiv},
arxivId = {1611.06455},
author = {Wang, Zhiguang and Yan, Weizhong and Oates, Tim},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2017.7966039},
eprint = {1611.06455},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Yan, Oates - Unknown - Time Series Classification from Scratch with Deep Neural Networks A Strong Baseline.pdf:pdf},
isbn = {9781509061815},
pages = {1578--1585},
title = {{Time series classification from scratch with deep neural networks: A strong baseline}},
url = {https://github.com/cauchyturing/},
volume = {2017-May},
year = {2017}
}
@inproceedings{Ren2019,
abstract = {Large companies need to monitor various metrics (for example, Page Views and Revenue) of their applications and services in real time. At Microsoft, we develop a time-series anomaly detection service which helps customers to monitor the time-series continuously and alert for potential incidents on time. In this paper, we introduce the pipeline and algorithm of our anomaly detection service, which is designed to be accurate, efficient and general. The pipeline consists of three major modules, including data ingestion, experimentation platform and online compute. To tackle the problem of time-series anomaly detection, we propose a novel algorithm based on Spectral Residual (SR) and Convolutional Neural Network (CNN). Our work is the first attempt to borrow the SR model from visual saliency detection domain to time-series anomaly detection. Moreover, we innovatively combine SR and CNN together to improve the performance of SR model. Our approach achieves superior experimental results compared with state-of-the-art baselines on both public datasets and Microsoft production data.},
archivePrefix = {arXiv},
arxivId = {1906.03821},
author = {Ren, Hansheng and Xu, Bixiong and Wang, Yujing and Yi, Chao and Huang, Congrui and Kou, Xi-Aoyu and Xing, Tony and Yang, Mao and Tong, Jie and Zhang, Qi},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/3292500.3330680},
eprint = {1906.03821},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Ren et al. - 2019 - Time-Series Anomaly Detection Service at Microsoft.pdf:pdf},
isbn = {9781450362016},
keywords = {Anomaly detection,Spectral Residual,Time-series},
pages = {3009--3017},
title = {{Time-series anomaly detection service at Microsoft}},
url = {https://doi.org/10.1145/3292500.3330680},
volume = {19},
year = {2019}
}
@article{Zhang2010,
abstract = {â€¢ The selection of the presented algorithms is somewhat arbitraryâ€¢ Please don't mind if your favorite algorithm is missingâ€¢ Please don t mind if your favorite algorithm is missingâ€¢ Anyway you should be able to classify any other algorithm not covered here by means of which of ... $\backslash$n},
author = {Zhang, Yang and Meratnia, Nirvana and Havinga, Paul},
doi = {10.1109/SURV.2010.021510.00088},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Meratnia, Havinga - 2010 - Outlier detection techniques for wireless sensor networks A survey.pdf:pdf},
issn = {1553877X},
journal = {IEEE Communications Surveys and Tutorials},
keywords = {Outlier,Outlier detection,Taxonomy,Wireless sensor networks},
number = {2},
pages = {159--170},
publisher = {IEEE},
title = {{Outlier detection techniques for wireless sensor networks: A survey}},
volume = {12},
year = {2010}
}
@inproceedings{Salimans2016,
abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3{\%}. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
archivePrefix = {arXiv},
arxivId = {1606.03498},
author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1606.03498},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Salimans et al. - Unknown - Improved Techniques for Training GANs.pdf:pdf},
issn = {10495258},
pages = {2234--2242},
title = {{Improved techniques for training GANs}},
url = {https://github.com/openai/},
year = {2016}
}
@article{IsmailFawaz2019,
abstract = {Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.},
annote = {picture with all deep learning models
generative/discriminative},
archivePrefix = {arXiv},
arxivId = {1809.04356},
author = {{Ismail Fawaz}, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre Alain},
doi = {10.1007/s10618-019-00619-1},
eprint = {1809.04356},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Fawaz et al. - Unknown - Deep learning for time series classification a review.pdf:pdf},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Classification,Deep learning,Review,Time series},
number = {4},
pages = {917--963},
title = {{Deep learning for time series classification: a review}},
url = {https://doi.org/10.1007/s10618-019-00619-1.},
volume = {33},
year = {2019}
}
@article{Rumelhart1986b,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure 1. {\textcopyright} 1986 Nature Publishing Group.},
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/naturebp.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {6088},
pages = {533--536},
title = {{Learning representations by back-propagating errors}},
volume = {323},
year = {1986}
}
@article{Kiran2018,
abstract = {Videos represent the primary source of information for surveillance applications. Video material is often available in large quantities but in most cases it contains little or no annotation for supervised learning. This article reviews the state-of-the-art deep learning based methods for video anomaly detection and categorizes them based on the type of model and criteria of detection. We also perform simple studies to understand the different approaches and provide the criteria of evaluation for spatio-temporal anomaly detection.},
archivePrefix = {arXiv},
arxivId = {1801.03149},
author = {Kiran, B. Ravi and Thomas, Dilip Mathew and Parakkal, Ranjith},
doi = {10.3390/jimaging4020036},
eprint = {1801.03149},
file = {:Users/EmilAndersson/Documents/Emil Andersson/Utbildning/Universitet/Exjobb/Multivariate-anomaly-detection/Papers/jimaging-04-00036.pdf:pdf},
issn = {2313433X},
journal = {Journal of Imaging},
keywords = {Anomaly detection,Autoencoders,Generative adversarial networks,LSTMs,Predictive models,Representation learning,Unsupervised methods,Variational Autoencoders},
number = {2},
title = {{An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos}},
volume = {4},
year = {2018}
}
@inproceedings{Malhotra2015a,
abstract = {Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The efficacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset.},
author = {Malhotra, Pankaj and Vig, Lovekesh and Shroff, Gautam and Agarwal, Puneet},
booktitle = {23rd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2015 - Proceedings},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Malhotra et al. - 2015 - Long Short Term Memory Networks for Anomaly Detection in Time Series.pdf:pdf},
isbn = {9782875870148},
pages = {89--94},
title = {{Long Short Term Memory networks for anomaly detection in time series}},
url = {http://www.i6doc.com/en/.},
year = {2015}
}
@article{Laptev2015,
abstract = {This paper introduces a generic and scalable framework for automated anomaly detection on large scale time-series data. Early detection of anomalies plays a key role in maintaining consistency of person's data and protects corporations against malicious attackers. Current state of the art anomaly detection approaches suffer from scalability, use-case restrictions, difficulty of use and a large number of false positives. Our system at Yahoo, EGADS, uses a collection of anomaly detection and forecasting models with an anomaly filtering layer for accurate and scalable anomaly detection on time-series. We compare our approach against other anomaly detection systems on real and synthetic data with varying time-series characteristics. We found that our framework allows for 50-60{\%} improvement in precision and recall for a variety of use-cases. Both the data and the framework are being open-sourced. The open-sourcing of the data, in particular, represents the first of its kind effort to establish the standard benchmark for anomaly detection.},
annote = {No method individually is good enough.

Outlier detection is grouped into two classes of algorithms:
Plug-in methods
Model the normal behavior of the time-series such that a significant deviation from this model is considered an out- lier. To model the normal behavior of the input time-series we can plug-in a wide range of time-series modeling and fore- casting models (e.g. ARIMA, Exponential Smoothing, Kalman Filter, State Space Models, etc.) depending on the application and the nature of time-series.
Decomposition-based methods
The decomposition of time-series can be done both in the time-domain via smoothing or in the frequency-domain via spectral decomposition. The frequency-domain methods can be further divided into parameteric and non-parametric methods.},
author = {Laptev, Nikolay and Amizadeh, Saeed and Flint, Ian},
doi = {10.1145/2783258.2788611},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Laptev, Amizadeh, Flint - 2015 - Generic and Scalable Framework for Automated Time-series Anomaly Detection.pdf:pdf},
pages = {1939--1947},
title = {{Generic and Scalable Framework for Automated Time-series Anomaly Detection}},
year = {2015}
}
@article{Bay,
author = {Bay, Stephen and Saito, Kazumi and Ueda, Naonori and Langley, Pat},
journal = {Center for the Study of Language and Information},
keywords = {0,36 q24,5,5a24,7,724,7h4,8bh4,a,b3,h4,u d bh4,xta uh4},
pages = {1},
title = {{A framework for discovering anomalous regimes in multivariate time-series data with local models}},
url = {http://www.stephenbay.net/papers/darts.ps},
volume = {1}
}
@article{Mogren2016,
abstract = {Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs.},
archivePrefix = {arXiv},
arxivId = {1611.09904},
author = {Mogren, Olof},
eprint = {1611.09904},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Mogren - Unknown - C-RNN-GAN Continuous recurrent neural networks with adversarial training.pdf:pdf},
title = {{C-RNN-GAN: Continuous recurrent neural networks with adversarial training}},
url = {https://github.com/olofmogren/c-rnn-gan http://arxiv.org/abs/1611.09904},
year = {2016}
}
@article{Bagnall2017,
abstract = {In the last 5 years there have been a large number of new time series classification algorithms proposed in the literature. These algorithms have been evaluated on subsets of the 47 data sets in the University of California, Riverside time series classification archive. The archive has recently been expanded to 85 data sets, over half of which have been donated by researchers at the University of East Anglia. Aspects of previous evaluations have made comparisons between algorithms difficult. For example, several different programming languages have been used, experiments involved a single train/test split and some used normalised data whilst others did not. The relaunch of the archive provides a timely opportunity to thoroughly evaluate algorithms on a larger number of datasets. We have implemented 18 recently proposed algorithms in a common Java framework and compared them against two standard benchmark classifiers (and each other) by performing 100 resampling experiments on each of the 85 datasets. We use these results to test several hypotheses relating to whether the algorithms are significantly more accurate than the benchmarks and each other. Our results indicate that only nine of these algorithms are significantly more accurate than both benchmarks and that one classifier, the collective of transformation ensembles, is significantly more accurate than all of the others. All of our experiments and results are reproducible: we release all of our code, results and experimental details and we hope these experiments form the basis for more robust testing of new algorithms in the future.},
author = {Bagnall, Anthony and Lines, Jason and Bostrom, Aaron and Large, James and Keogh, Eamonn},
doi = {10.1007/s10618-016-0483-9},
file = {:Users/EmilAndersson/Library/Application Support/Mendeley Desktop/Downloaded/Bagnall et al. - 2017 - The great time series classification bake off a review and experimental evaluation of recent algorithmic advance.pdf:pdf},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Elastic distance measures,Shapelets,Time series classification,Time series similarity},
month = {may},
number = {3},
pages = {606--660},
publisher = {Springer US},
title = {{The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances}},
url = {http://link.springer.com/10.1007/s10618-016-0483-9},
volume = {31},
year = {2017}
}
