%-----------------------%
%------Background-------%
%-----------------------%

% Introduction
Probabilistic computations that arise in maximum likelihood estimation and similar methods are in many cases difficult to approximate. Generative Adversarial Network (GAN) is a framework that bypass some of these difficulties. A GAN consists of two major models; a generative model and a discriminative model. The generative model produces a sample and the discriminative model determines if the sample is from the distribution of the generative model or the distribution of the real data. These two models compete and the generative models improves with the goal of generating more realistic data and the discriminative model improves with the goal of being able to differentiate between real and generated data. 

% GAN framework
In the framework, both the generator and the discriminator are neural networks. Random noise is sampled from a latent space and forward propagated through the generator, the generator can then be trained with backpropagation and gradient descent to generate data that follows the wanted distribution. This procedure enables approximations to be made without using Markov chains and approximate inference.  

%-- GAN with multivariate time series --%
The generative capacity of Generative Adversarial Networks (GANs) have previously been shown to be effective in image analysis for generating images that follow a certain distribution. Recent work has shown that it could also be used to effectively generate multivariate time series. In anomaly detection this generative ability could be used to reconstruct samples of time series by first mapping them back to the latent space. The samples that doesn't follow the learned distribution reconstructs with an error and can be classified as anomalies. 

%-- Disadvantages --%
The GAN framework is making it possible to use a wide variety of cost functions that measure the distance between the real and the generated distribution. But they also have several disadvantages. 

% Interpretability 

% Stability

% Mode collapse

% Vanishing gradient



\subsection{Wasserstein Generative Adversarial Network}

% Earth Movers Distance
% Lipschitz constraint


%%% What to include? %%%
%Generator
%Discriminator

%Neural Nets
%RNN
%LSTM
%-Unidirectional
%-Bidirectional

%Loss function
%-Binary crossentropy

%Optimizer 
%Gradient-based: Adam, RMSProp

%Mapping to latent space
%Gradient-based: Adam




%\subsection{Loss function}

%KL-divergence
%JS-divergence
%Minimax

%{https://developers.google.com/machine-learning/gan/loss} copied
%GANs try to replicate a probability distribution. They should therefore use \textbf{loss functions} that reflect the distance between the distribution of the data generated by the GAN and the distribution of the real data.

%How do you capture the difference between two distributions in GAN loss functions? This question is an area of active research, and many approaches have been proposed.  Two common GAN loss functions are:
%\begin{itemize}
%\item \textbf{minimax loss:} The loss function used in the paper that introduced GANs.
%\item \textbf{Wasserstein loss:} First described in a 2017 paper.
%\end{itemize}

%\subsubsection{Modified minimax loss}
%The original GAN paper notes that the above minimax loss function can cause the GAN to get stuck in the early stages of GAN training when the discriminator's job is very easy. The paper therefore suggests modifying the generator loss so that the generator tries to maximize log D(G(z)).

%\subsubsection{Wasserstein loss}
%This loss function depends on a modification of the GAN scheme (called "Wasserstein GAN" or "WGAN") in which the discriminator does not actually classify instances. For each instance it outputs a number. This number does not have to be less than one or greater than 0, so we can't use 0.5 as a threshold to decide whether an instance is real or fake. Discriminator training just tries to make the output bigger for real instances than for fake instances.

%Because it can't really discriminate between real and fake, the WGAN discriminator is actually called a "critic" instead of a "discriminator". This distinction has theoretical importance, but for practical purposes we can treat it as an acknowledgement that the inputs to the loss functions don't have to be probabilities.

%The discriminator tries to maximize the difference between its output on real instances and its output on fake instances. The generator tries to maximize the discriminator's output for its fake instances. The theoretical justification for the Wasserstein GAN (or WGAN) requires that the weights throughout the GAN be clipped so that they remain within a constrained range.

%Certain benefits come with it. Wasserstein GANs are less vulnerable to getting stuck than minimax-based GANs, and avoid problems with vanishing gradients. The earth mover distance also has the advantage of being a true metric: a measure of distance in a space of probability distributions. Cross-entropy is not a metric in this sense.

%\subsection{Problems}
%https://developers.google.com/machine-learning/gan/problems

%\subsubsection{Vanishing gradient}
%Research has suggested that if your discriminator is too good, then generator training can fail due to vanishing gradients. In effect, an optimal discriminator doesn't provide enough information for the generator to make progress.

%In machine learning, the vanishing gradient problem is a difficulty found in training artificial neural networks with gradient-based learning methods and backpropagation. In such methods, each of the neural network's weights receives an update proportional to the partial derivative of the error function with respect to the current weight in each iteration of training. The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value.

%\textbf{Remedies:}
%\begin{itemize}
%\item \textbf{Wasserstein loss:} The Wasserstein loss is designed to prevent vanishing gradients even when you train the discriminator to optimality.
%\item \textbf{Modified minimax loss:} The original GAN paper proposed a modification to minimax loss to deal with vanishing gradients.
%\end{itemize}


%\subsubsection{Mode collapse}
%Usually you want your GAN to produce a wide variety of outputs. You want, for example, a different face for every random input to your face generator.

%However, if a generator produces an especially plausible output, the generator may learn to produce only that output. In fact, the generator is always trying to find the one output that seems most plausible to the discriminator.

%If the generator starts producing the same output (or a small set of outputs) over and over again, the discriminator's best strategy is to learn to always reject that output. But if the next generation of discriminator gets stuck in a local minimum and doesn't find the best strategy, then it's too easy for the next generator iteration to find the most plausible output for the current discriminator.

%Each iteration of generator over-optimizes for a particular discriminator, and the discriminator never manages to learn its way out of the trap. As a result the generators rotate through a small set of output types. This form of GAN failure is called \textbf{mode collapse}.

%The following approaches try to force the generator to broaden its scope by preventing it from optimizing for a single fixed discriminator:
%\begin{itemize}
%\item \textbf{Wasserstein loss:} The Wasserstein loss alleviates mode collapse by letting you train the discriminator to optimality without worrying about vanishing gradients. If the discriminator doesn't get stuck in local minima, it learns to reject the outputs that the generator stabilizes on. So the generator has to try something new.
%\item \textbf{Unrolled GANs:} Unrolled GANs use a generator loss function that incorporates not only the current discriminator's classifications, but also the outputs of future discriminator versions. So the generator can't over-optimize for a single discriminator.
%\end{itemize}

%\subsubsection{Failure to converge}
%GANs frequently fail to converge, as discussed in the module on training.

%Researchers have tried to use various forms of regularization to improve GAN convergence, including:
%\begin{itemize}
%\item Adding noise to discriminator inputs
%\item Penalizing discriminator weights
%\end{itemize}

